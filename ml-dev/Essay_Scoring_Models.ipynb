{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SUjaSrAtryJ",
        "outputId": "56c91df0-119f-4efb-9e44-4e1387ff3424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post1)\n"
          ]
        }
      ],
      "source": [
        "! pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Sv17hzafuIc3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8d9S-4JJuV-B"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = \"../content/\"\n",
        "GLOVE_DIR = './glove.6B/'\n",
        "SAVE_DIR = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EirNAdNduhud",
        "outputId": "862f03ce-612a-489c-d0c1-44fec3ace40c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f0171a43-1537-462c-9900-f86a2510c6d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12971</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12972</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12976 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0171a43-1537-462c-9900-f86a2510c6d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0171a43-1537-462c-9900-f86a2510c6d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0171a43-1537-462c-9900-f86a2510c6d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       essay_id  essay_set                                              essay  \\\n",
              "0             1          1  Dear local newspaper, I think effects computer...   \n",
              "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "...         ...        ...                                                ...   \n",
              "12971     21626          8   In most stories mothers and daughters are eit...   \n",
              "12972     21628          8   I never understood the meaning laughter is th...   \n",
              "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
              "12974     21630          8                                 Trippin' on fen...   \n",
              "12975     21633          8   Many people believe that laughter can improve...   \n",
              "\n",
              "       domain1_score  \n",
              "0                  8  \n",
              "1                  9  \n",
              "2                  7  \n",
              "3                 10  \n",
              "4                  8  \n",
              "...              ...  \n",
              "12971             35  \n",
              "12972             32  \n",
              "12973             40  \n",
              "12974             40  \n",
              "12975             40  \n",
              "\n",
              "[12976 rows x 4 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
        "y = X['domain1_score']\n",
        "X = X.dropna(axis=1)\n",
        "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ym2cYTOovKGX"
      },
      "outputs": [],
      "source": [
        "min_scores = np.array([-1, 2, 1, 0, 0, 0, 0, 0, 0])\n",
        "max_scores = np.array([-1, 12, 6, 3, 3, 4, 4, 30, 60])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oK7QoHjQvNOI",
        "outputId": "ac37edd3-f704-47bb-b28b-013651ca441c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-694bf4f6-cea8-41bb-a5fa-84ad603ce46e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12971</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>In most stories mothers and daughters are eit...</td>\n",
              "      <td>35</td>\n",
              "      <td>58.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12972</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>I never understood the meaning laughter is th...</td>\n",
              "      <td>32</td>\n",
              "      <td>53.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>Trippin' on fen...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>Many people believe that laughter can improve...</td>\n",
              "      <td>40</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12976 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-694bf4f6-cea8-41bb-a5fa-84ad603ce46e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-694bf4f6-cea8-41bb-a5fa-84ad603ce46e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-694bf4f6-cea8-41bb-a5fa-84ad603ce46e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       essay_id  essay_set                                              essay  \\\n",
              "0             1          1  Dear local newspaper, I think effects computer...   \n",
              "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "...         ...        ...                                                ...   \n",
              "12971     21626          8   In most stories mothers and daughters are eit...   \n",
              "12972     21628          8   I never understood the meaning laughter is th...   \n",
              "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
              "12974     21630          8                                 Trippin' on fen...   \n",
              "12975     21633          8   Many people believe that laughter can improve...   \n",
              "\n",
              "       domain1_score      score  \n",
              "0                  8  60.000000  \n",
              "1                  9  70.000000  \n",
              "2                  7  50.000000  \n",
              "3                 10  80.000000  \n",
              "4                  8  60.000000  \n",
              "...              ...        ...  \n",
              "12971             35  58.333333  \n",
              "12972             32  53.333333  \n",
              "12973             40  66.666667  \n",
              "12974             40  66.666667  \n",
              "12975             40  66.666667  \n",
              "\n",
              "[12976 rows x 5 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "old_min = min_scores[X['essay_set']]\n",
        "old_max = max_scores[X['essay_set']]\n",
        "old_range = old_max - old_min\n",
        "new_min = 0\n",
        "new_max = 100\n",
        "new_range = (new_max - new_min)  \n",
        "X['score'] = (((X['domain1_score'] - old_min) * new_range) / old_range) + new_min\n",
        "\n",
        "y = np.round(X['score'])\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEULgzV_vW1P",
        "outputId": "626660b2-df1e-4309-96fb-7bfd3366c491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        60.0\n",
              "1        70.0\n",
              "2        50.0\n",
              "3        80.0\n",
              "4        60.0\n",
              "         ... \n",
              "12971    58.0\n",
              "12972    53.0\n",
              "12973    67.0\n",
              "12974    67.0\n",
              "12975    67.0\n",
              "Name: score, Length: 12976, dtype: float64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyLR33CYvaBv",
        "outputId": "3d2bb116-1da4-400e-8029-c82edeb1473d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def essays_to_wordlist(essay_v, remove_stopwords):\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)\n",
        "\n",
        "def essays_to_sentences(essay_v, remove_stopwords):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(essays_to_wordlist(raw_sentence, remove_stopwords))\n",
        "    return sentences\n",
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    # index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec, model[word])       \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8cJNB6j4wIDh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, model_from_config\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def getmodel():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(200, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 200], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "e-ntpI7Ywbz7"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for essay in X['essay']:\n",
        "    corpus.append(essays_to_wordlist(essay, True))\n",
        "\n",
        "embedding_dict={}\n",
        "with open('/content/glove.6B.200d.txt','r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word] = vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuAW1_J522DL",
        "outputId": "8fa8c687-3bc3-41aa-cd2e-23e857b3e476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 7s 13ms/step - loss: 2695.3765 - mae: 46.9714\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 1949.6932 - mae: 38.7980\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 1429.2015 - mae: 32.0593\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 1043.5739 - mae: 26.6990\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 778.4189 - mae: 22.7254\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 638.7564 - mae: 20.4068\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 589.7532 - mae: 19.3711\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 558.4670 - mae: 18.7797\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 520.0529 - mae: 18.0772\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 503.3887 - mae: 17.7400\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 481.7130 - mae: 17.3275\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 480.8514 - mae: 17.2716\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 467.5346 - mae: 17.0016\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 462.0226 - mae: 16.8741\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 449.4782 - mae: 16.6635\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 445.0779 - mae: 16.6055\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 436.4452 - mae: 16.4738\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 428.8314 - mae: 16.2111\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 426.5403 - mae: 16.2151\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 430.0715 - mae: 16.2158\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 425.4698 - mae: 16.2416\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 417.1305 - mae: 15.9731\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 413.1328 - mae: 15.8999\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 411.0186 - mae: 15.8764\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 412.6437 - mae: 15.9238\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 398.5250 - mae: 15.6562\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 401.5821 - mae: 15.6604\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 3s 16ms/step - loss: 393.4536 - mae: 15.5651\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 397.4453 - mae: 15.6104\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 394.5963 - mae: 15.5341\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 383.7095 - mae: 15.3074\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 381.4310 - mae: 15.2825\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 388.3253 - mae: 15.4281\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 375.9395 - mae: 15.1502\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 381.7986 - mae: 15.2669\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 379.3322 - mae: 15.1984\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 370.6575 - mae: 15.0560\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 365.4850 - mae: 14.9766\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 367.3591 - mae: 15.0426\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 363.7144 - mae: 14.9752\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 362.7629 - mae: 14.8873\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 362.7509 - mae: 14.9103\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 359.1331 - mae: 14.8882\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 354.6569 - mae: 14.7650\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 359.2153 - mae: 14.8778\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 357.4159 - mae: 14.8077\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 353.4624 - mae: 14.6830\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 343.4424 - mae: 14.5404\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 352.2256 - mae: 14.6820\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 349.1424 - mae: 14.6352\n",
            "82/82 [==============================] - 1s 2ms/step\n",
            "Kappa Score: 0.641314631670654\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 7s 12ms/step - loss: 2710.2917 - mae: 47.1270\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 1968.8918 - mae: 39.0435\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 1447.2769 - mae: 32.3270\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 1059.3857 - mae: 26.9334\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 787.5435 - mae: 22.8920\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 647.6708 - mae: 20.5312\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 602.9741 - mae: 19.5807\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 564.1358 - mae: 18.8819\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 532.1075 - mae: 18.3229\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 503.2560 - mae: 17.6913\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 493.2769 - mae: 17.4434\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 486.9568 - mae: 17.3269\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 470.7195 - mae: 17.0701\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 465.2715 - mae: 16.9749\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 462.5331 - mae: 16.8472\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 455.8019 - mae: 16.7379\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 446.8802 - mae: 16.6228\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 440.0714 - mae: 16.4727\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 4s 25ms/step - loss: 432.3795 - mae: 16.3174\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 434.0771 - mae: 16.3167\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 417.2641 - mae: 16.0276\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 416.9906 - mae: 15.9923\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 412.4106 - mae: 15.8200\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 411.0051 - mae: 15.8378\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 398.4544 - mae: 15.6184\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 404.8788 - mae: 15.7110\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 397.3921 - mae: 15.6288\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 397.0902 - mae: 15.5872\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 397.3655 - mae: 15.5754\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 391.6508 - mae: 15.5171\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 380.2152 - mae: 15.2167\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 379.6285 - mae: 15.2477\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 376.7967 - mae: 15.2061\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 378.1795 - mae: 15.1579\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 377.0359 - mae: 15.1653\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 366.0996 - mae: 14.9294\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 373.4047 - mae: 15.1276\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 367.0715 - mae: 15.0638\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 361.6155 - mae: 14.9526\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 367.6601 - mae: 14.9310\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 360.1048 - mae: 14.8695\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 362.4569 - mae: 14.8863\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 359.8421 - mae: 14.8125\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 358.6660 - mae: 14.8533\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 354.6646 - mae: 14.7663\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 354.0963 - mae: 14.7341\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 351.4822 - mae: 14.6366\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 350.0390 - mae: 14.6658\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 350.9711 - mae: 14.7204\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 341.6187 - mae: 14.4221\n",
            "82/82 [==============================] - 1s 2ms/step\n",
            "Kappa Score: 0.60721109166162\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 6s 13ms/step - loss: 2791.3347 - mae: 47.9302\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 2044.5535 - mae: 39.9516\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 1508.1562 - mae: 33.1002\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 1093.8152 - mae: 27.3903\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 812.7733 - mae: 23.2324\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 658.6552 - mae: 20.6991\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 606.3831 - mae: 19.6631\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 594.6164 - mae: 19.4561\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 562.3715 - mae: 18.8718\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 526.8784 - mae: 18.2022\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 506.8919 - mae: 17.8455\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 491.9439 - mae: 17.5089\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 480.9946 - mae: 17.2847\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 475.5305 - mae: 17.1321\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 476.6897 - mae: 17.1753\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 466.7794 - mae: 16.9123\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 455.0403 - mae: 16.7481\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 454.2607 - mae: 16.6881\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 453.8797 - mae: 16.7096\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 445.2165 - mae: 16.5068\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 441.7182 - mae: 16.5215\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 433.0582 - mae: 16.3461\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 428.5869 - mae: 16.2879\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 425.0031 - mae: 16.1185\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 422.5004 - mae: 16.0415\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 419.4046 - mae: 16.0070\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 412.9116 - mae: 15.8632\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 409.1018 - mae: 15.8508\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 406.5427 - mae: 15.8043\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 402.9293 - mae: 15.6871\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 391.5569 - mae: 15.4671\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 393.5576 - mae: 15.4623\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 392.3357 - mae: 15.5097\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 386.6892 - mae: 15.3489\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 386.4368 - mae: 15.3793\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 374.3927 - mae: 15.1188\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 380.0013 - mae: 15.2131\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 378.7460 - mae: 15.2093\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 375.3247 - mae: 15.1162\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 370.3289 - mae: 15.0215\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 369.8867 - mae: 15.0605\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 362.2643 - mae: 14.8594\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 368.1179 - mae: 15.0350\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 362.0876 - mae: 14.9225\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 362.5185 - mae: 14.8762\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 360.3191 - mae: 14.8323\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 356.8035 - mae: 14.7771\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 359.7092 - mae: 14.7705\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 360.3171 - mae: 14.7789\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 351.2407 - mae: 14.6817\n",
            "82/82 [==============================] - 1s 2ms/step\n",
            "Kappa Score: 0.6536085478599438\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 7s 13ms/step - loss: 2770.7175 - mae: 47.6800\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 2026.8989 - mae: 39.6699\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 1488.6387 - mae: 32.8062\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 1089.2021 - mae: 27.3388\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 807.1587 - mae: 23.2522\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 651.8361 - mae: 20.6601\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 600.6367 - mae: 19.5806\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 606.7176 - mae: 19.6128\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 599.1443 - mae: 19.4926\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 549.7080 - mae: 18.6978\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 517.7578 - mae: 17.9376\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 500.1569 - mae: 17.6025\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 495.9356 - mae: 17.5342\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 483.3445 - mae: 17.2918\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 477.4318 - mae: 17.1774\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 475.8943 - mae: 17.2018\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 472.1339 - mae: 17.0781\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 461.6290 - mae: 16.8493\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 453.4842 - mae: 16.6595\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 452.9261 - mae: 16.7028\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 15ms/step - loss: 440.2886 - mae: 16.4448\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 434.4385 - mae: 16.3523\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 435.7307 - mae: 16.3037\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 429.9737 - mae: 16.2307\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 426.4243 - mae: 16.1462\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 426.1900 - mae: 16.1244\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 414.8345 - mae: 15.9176\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 414.2611 - mae: 15.8646\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 409.0730 - mae: 15.7717\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 405.9498 - mae: 15.7454\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 396.7509 - mae: 15.5713\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 399.8623 - mae: 15.6321\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 397.6462 - mae: 15.5973\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 391.8457 - mae: 15.4196\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 392.2480 - mae: 15.4655\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 387.0945 - mae: 15.3829\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 386.8076 - mae: 15.3415\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 387.7647 - mae: 15.4137\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 380.1539 - mae: 15.2615\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 376.4856 - mae: 15.2040\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 379.0415 - mae: 15.2029\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 376.1588 - mae: 15.2192\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 372.7988 - mae: 15.1287\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 371.4593 - mae: 15.0491\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 3s 21ms/step - loss: 367.7699 - mae: 14.9422\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 358.6753 - mae: 14.7701\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 366.2711 - mae: 14.9437\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 356.7360 - mae: 14.7604\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 359.0690 - mae: 14.7961\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 355.4384 - mae: 14.6598\n",
            "82/82 [==============================] - 1s 2ms/step\n",
            "Kappa Score: 0.6393025521267555\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 1, 200)            320800    \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,705\n",
            "Trainable params: 388,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 6s 13ms/step - loss: 2761.1919 - mae: 47.5905\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 2013.5116 - mae: 39.4924\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 1479.4146 - mae: 32.7737\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 1081.7509 - mae: 27.2301\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 803.9671 - mae: 23.1978\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 659.7219 - mae: 20.7522\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 611.6605 - mae: 19.7526\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 572.1439 - mae: 18.9976\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 537.2656 - mae: 18.3868\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 509.7957 - mae: 17.8024\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 500.7234 - mae: 17.5998\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 492.1029 - mae: 17.4610\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 473.2002 - mae: 17.0566\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 470.6738 - mae: 17.0220\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 457.8473 - mae: 16.8701\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 455.7519 - mae: 16.7540\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 450.5770 - mae: 16.7118\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 441.0055 - mae: 16.4858\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 441.8009 - mae: 16.4706\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 433.7192 - mae: 16.3564\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 436.5486 - mae: 16.3414\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 423.1548 - mae: 16.0789\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 423.4195 - mae: 15.9897\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 422.8113 - mae: 16.0873\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 419.9676 - mae: 15.9778\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 411.5107 - mae: 15.9107\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 406.2383 - mae: 15.7228\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 402.6611 - mae: 15.6880\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 404.8078 - mae: 15.6686\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 398.4165 - mae: 15.6592\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 398.7748 - mae: 15.5156\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 394.4067 - mae: 15.5382\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 390.2031 - mae: 15.4590\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 384.8600 - mae: 15.2859\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 389.0659 - mae: 15.3575\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 384.4311 - mae: 15.3829\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 384.2945 - mae: 15.3467\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 375.1331 - mae: 15.1763\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 376.6042 - mae: 15.1653\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 368.8218 - mae: 15.0112\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 368.8965 - mae: 14.9852\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 370.6953 - mae: 15.0823\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 369.0209 - mae: 15.0151\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 366.7450 - mae: 14.9927\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 369.6167 - mae: 14.9943\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 362.1642 - mae: 14.9229\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 355.9780 - mae: 14.7215\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 355.5019 - mae: 14.7447\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 356.4733 - mae: 14.7395\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 356.1221 - mae: 14.7946\n",
            "82/82 [==============================] - 1s 2ms/step\n",
            "Kappa Score: 0.6615406272163109\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(X):\n",
        "    \n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "    \n",
        "    sentences = []\n",
        "    \n",
        "    for essay in train_essays:\n",
        "        sentences += essays_to_sentences(essay, remove_stopwords = True)\n",
        "\n",
        "    num_features = 200 \n",
        "\n",
        "    model = embedding_dict\n",
        "\n",
        "    clean_train_essays = []\n",
        "    for essay_v in train_essays:\n",
        "        clean_train_essays.append(essays_to_wordlist(essay_v, remove_stopwords=True))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "    \n",
        "    clean_test_essays = []\n",
        "    for essay_v in test_essays:\n",
        "        clean_test_essays.append(essays_to_wordlist( essay_v, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "    \n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    \n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    \n",
        "    lstm_model = getmodel()\n",
        "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "\n",
        "    if count == 5:\n",
        "         lstm_model.save('./content/final_lstm.h5')\n",
        "\n",
        "    y_pred = np.round(y_pred)\n",
        "    \n",
        "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x20TL4CA7Auf",
        "outputId": "487f4edc-df29-4a74-e481-a8837720f3d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Kappa score after a 5-fold cross validation:  0.6406\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Kappa score after a 5-fold cross validation: \", np.around(np.array(results).mean(),decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SXr1zhQ7MqK",
        "outputId": "00a7fb4b-2be4-43b8-e26d-0e7286362b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "[[67.]]\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "contentBad = \"\"\"\n",
        "        In “Let there be dark,” Paul Bogard talks about the importance of darkness.\n",
        "Darkness is essential to humans. Bogard states, “Our bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of “short sleep” is “long light.” Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isn’t a place for this much artificial light in our lives.” (Bogard 2). Here, Bogard talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy.\n",
        "Animals also need darkness. Bogard states, “The rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well known—the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggs—and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the world’s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earth’s ecology would collapse...” (Bogard 2). Here Bogard explains that animals, too, need darkness to survive.\n",
        "    \"\"\" \n",
        "\n",
        "content = contentBad\n",
        "    \n",
        "if len(content) > 20:\n",
        "    num_features = 200\n",
        "    clean_test_essays = []\n",
        "    clean_test_essays.append(essays_to_wordlist( content, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "\n",
        "    preds = lstm_model.predict(testDataVecs)\n",
        "\n",
        "    if math.isnan(preds):\n",
        "        preds = 0\n",
        "    else:\n",
        "      preds = np.round(preds)\n",
        "\n",
        "    if preds < 0:\n",
        "        preds = 0\n",
        "else:\n",
        "    preds = 0\n",
        "    \n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nBivnTD-8MA6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(lstm_model, open('model_fix.pkl','wb'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "14958d3aee5f1cad06795f787e54b96185c25fb40dfec723a5be941f3a531b8c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
